{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1714\n",
       "1      1254\n",
       "2      1639\n",
       "3      1118\n",
       "4      1499\n",
       "       ... \n",
       "673    1074\n",
       "674    1044\n",
       "675    1078\n",
       "676    1055\n",
       "677    1394\n",
       "Name: StudentID, Length: 678, dtype: int64"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('X_train.csv')\n",
    "train_Student_ID = X.pop('StudentID')\n",
    "y = pd.read_csv('y_train.csv')\n",
    "y.pop('StudentID')\n",
    "\n",
    "# X_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(678, 32)\n",
      "(678, 58)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Categorical encoding\n",
    "\n",
    "cat_vars = [\"school\", \"sex\", \"address\",\"famsize\",\"Pstatus\", \"Mjob\", \"Fjob\", \"reason\", \"guardian\", \"schoolsup\", \"famsup\",\"paid\",\"activities\",\"nursery\",\"higher\",\n",
    "\"internet\", \"romantic\"]\n",
    "\n",
    "# Numerical Variables to use\n",
    "num_vars = [\"age\", \"Medu\", \"Fedu\",\"absences\"]\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "    ('numerical', num_pipeline, num_vars),\n",
    "    ('categorical', OneHotEncoder(), cat_vars),\n",
    "], remainder=\"passthrough\")\n",
    "print(X.shape)\n",
    "X = data_pipeline.fit_transform(X, y)\n",
    "# print(\"****\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(474, 58)\n"
     ]
    }
   ],
   "source": [
    "# Creating validation and stuffs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.03134674922600619\n",
      "R2 Score\n",
      "-0.13706420454985535\n"
     ]
    }
   ],
   "source": [
    "# Choosing models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# forest = RandomForestClassifier(random_state=1)\n",
    "model = MLPClassifier(solver='sgd',learning_rate_init = 0.05, alpha=0.03, hidden_layer_sizes=(50,50,20), random_state=1, warm_start= True, max_iter=5000)\n",
    "# model = MLPClassifier(hidden_layer_sizes=(50,50,20), random_state=1, max_iter=1000, warm_start= True)\n",
    "\n",
    "# model = RandomForestClassifier(n_jobs = -1,warm_start = True, random_state=0, n_estimators=500, min_samples_leaf=200)\n",
    "\n",
    "# model = KNeighborsClassifier()\n",
    "# model = DecisionTreeClassifier(random_state=0)\n",
    "clf = MultiOutputClassifier(model, n_jobs=-1)\n",
    "\n",
    "# clf = RandomForestClassifier(n_jobs = -1,warm_start = True, random_state=0, n_estimators=500, criterion=\"gini\")\n",
    "\n",
    "# parameters = {'n_estimators':(100, 200, 500), 'criterion':(\"gini\", \"entropy\")}\n",
    "# clf = GridSearchCV(model, parameters)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print(clf.score(X_test, y_test))\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Testing with X_test\n",
    "from sklearn.metrics import f1_score, r2_score\n",
    "\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_test, clf.predict(X_test), average='weighted'))\n",
    "print(\"R2 Score\")\n",
    "print(r2_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MLPClassifier(alpha=0.03,\n",
       "                                              hidden_layer_sizes=(50, 50, 20),\n",
       "                                              learning_rate_init=0.3,\n",
       "                                              max_iter=5000, random_state=1,\n",
       "                                              solver='sgd', warm_start=True),\n",
       "                      n_jobs=-1)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(clf.best_params_)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFFAFASFASFASF*****\n",
      "F1 Score\n",
      "0.0171603358894814\n",
      "R2 Score\n",
      "-0.11084400049711052\n"
     ]
    }
   ],
   "source": [
    "# Trying with test set\n",
    "X_testMain = pd.read_csv('X_test.csv')\n",
    "y_testMain = pd.read_csv('./test_label/y_test.csv')\n",
    "\n",
    "X_testMain.pop('StudentID')\n",
    "y_testMain.pop('StudentID')\n",
    "\n",
    "X_testMain = data_pipeline.transform(X_testMain)\n",
    "\n",
    "print(\"AFFAFASFASFASF*****\")\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_testMain, clf.predict(X_testMain), average='weighted'))\n",
    "print(\"R2 Score\")\n",
    "print(r2_score(y_testMain, clf.predict(X_testMain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd54cb23c3ada7f153658cd17d5702cad9e7224189397133eb99d49b0a9367b7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
